# LLM Proxy Server Configuration

# Server Configuration
PORT=3001

# LLM Provider Configuration
# Options: openai, anthropic, goose
LLM_PROVIDER=openai

# API Keys (set at least one)
OPENAI_API_KEY=sk-your-openai-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Goose Integration (optional)
GOOSE_ENDPOINT=http://localhost:8080
GOOSE_API_KEY=your-goose-token

# Rate Limiting
REQUESTS_PER_MINUTE=10
